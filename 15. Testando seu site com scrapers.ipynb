{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CapÃ­tulo 15 - Testando seu site com scrapers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the test\n",
      "Tearing dwon the test\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "# Testando que 2 + 2 = 4\n",
    "\n",
    "class TestAddition(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        print('Setting up the test')\n",
    "\n",
    "    def tearDown(self) -> None:\n",
    "        print('Tearing dwon the test')\n",
    "\n",
    "    def test_twoPlusTwo(self):\n",
    "        total = 2 + 2\n",
    "        self.assertEqual(4, total);\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=[''], exit=False)\n",
    "    %reset\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 4.308s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Testando a Wikipedia\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import unittest\n",
    "\n",
    "class TestWikipedia(unittest.TestCase):\n",
    "    bs = None\n",
    "    def setUpClass():\n",
    "        url = 'http://en.wikipedia.org/wiki/Monty_Python'\n",
    "        TestWikipedia.bs = BeautifulSoup(urlopen(url), 'html.parser')\n",
    "\n",
    "    def test_titleText(self):\n",
    "        pageTitle = TestWikipedia.bs.find('h1').get_text()\n",
    "        self.assertEqual('Monty Python', pageTitle);\n",
    "\n",
    "    def test_contentExists(self):\n",
    "        content = TestWikipedia.bs.find('div',{'id':'mw-content-text'})\n",
    "        self.assertIsNotNone(content)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=[''], exit=False)\n",
    "    %reset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 25.519s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import unittest\n",
    "import re\n",
    "import random\n",
    "from urllib.parse import unquote\n",
    "\n",
    "class TestWikipedia(unittest.TestCase):\n",
    "\n",
    "    def test_PageProperties(self):\n",
    "        self.url = 'http://en.wikipedia.org/wiki/Monty_Python'\n",
    "        #Test the first 10 pages we encounter\n",
    "        for i in range(1, 10):\n",
    "            self.bs = BeautifulSoup(urlopen(self.url), 'html.parser')\n",
    "            titles = self.titleMatchesURL()\n",
    "            self.assertEqual(titles[0], titles[1])\n",
    "            self.assertTrue(self.contentExists())\n",
    "            self.url = self.getNextLink()\n",
    "        print('Done!')\n",
    "\n",
    "    def titleMatchesURL(self):\n",
    "        pageTitle = self.bs.find('h1').get_text()\n",
    "        urlTitle = self.url[(self.url.index('/wiki/')+6):]\n",
    "        urlTitle = urlTitle.replace('_', ' ')\n",
    "        urlTitle = unquote(urlTitle)\n",
    "        return [pageTitle.lower(), urlTitle.lower()]\n",
    "\n",
    "    def contentExists(self):\n",
    "        content = self.bs.find('div',{'id':'mw-content-text'})\n",
    "        if content is not None:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def getNextLink(self):\n",
    "        # Returns random link on page, using technique from Chapter 3\n",
    "        links = self.bs.find('div', {'id':'bodyContent'}).find_all('a', href=re.compile('^(/wiki/)((?!:).)*$'))\n",
    "        randomLink = random.SystemRandom().choice(links)\n",
    "        return 'https://wikipedia.org{}'.format(randomLink.attrs['href'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=[''], exit=False)\n",
    "    %reset"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
