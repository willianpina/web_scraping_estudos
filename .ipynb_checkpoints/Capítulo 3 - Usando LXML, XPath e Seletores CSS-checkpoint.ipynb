{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center><b>Capítulo 3</b></h1>\n",
    "<h1 align=center>Usando LXML, XPath e Seletores CSS</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Instrução ao XPath e seletor CSS</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>XPath</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **//** seleciona os nós no documento. Não importa onde eles estejam localizados.\n",
    "\n",
    "2. **//*** seleciona todos os elementos no documento.\n",
    "\n",
    "3. **//food** Seleciona todos os termos *food*\n",
    "\n",
    "4. **\\*** seleciona todos os elementos\n",
    "\n",
    "5. **//food/name | //food/price** seleciona o nome o preço dos elementos encontrados no nó *food*\n",
    "\n",
    "6. **//food/name** seleciona todos os nomes dentro do nó *food*\n",
    "\n",
    "7. **//food/name/text()** seleciona o texto somente de todos os elementos food/name \n",
    "\n",
    "8. **//food/name | //ratting** seleciona todos os elementos *name* que estão dentro de *food* e *rating* encontrados no documento.\n",
    "\n",
    "9. **//food[1]/name** seleciona o nome do elemento no primeiro nó dentro de food.\n",
    "\n",
    "10. **//food[feedback<9]** seleciona o food e todos os elementos onde a condição é verdadeira.\n",
    "\n",
    "11. **//food[last()]/name/text()** seleciona o texto do elemento nome do último nó de *food*\n",
    "\n",
    "12. **sum(//food/feedback)** soma o feedback encontrado em todos os nós food.\n",
    "\n",
    "13. **//food[rating>3 and rating <5]/name** seleciona o nome do food que preenche a condição.\n",
    "\n",
    "14. **//food/name[contains(., 'Juice')]** seleciona o nome da comida que contém a string Juice \n",
    "\n",
    "15. **//food/description[start-with(.,'Fresh')]/text()** seleciona o nó da descrição que começa com Fresh\n",
    "\n",
    "16. **//food[position()>3]** seleciona o primeiro e o segundo de acordo com a posição.\n",
    "\n",
    "17. **//book/@price** seleciona o price com um atributo para book. \n",
    "\n",
    "18. **//book/@id**  seleciona o atributo *id* e o valor dele. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>CSS</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Combinadores: \n",
    "* **+**: Seleciona o valor imediatamente após.\n",
    "* **>**: Seleciona o filho direto.\n",
    "* **~**: Seleciona o elemento que precede o parente.\n",
    "* **a[href$=\"pdf\"]**: Seleciona o atribudo final (sufixo)\n",
    "* **a[href*=abc]**: Seleciona o atributo href que contém abc\n",
    "* **a.plan**: elementos a com classe *plan*\n",
    "* **a#link**: elementos a que possuem atributo id de *Link*\n",
    "\n",
    "\n",
    "2. Seletores\n",
    "\n",
    "* h1: seleciona o elemento *h1* \n",
    "* a: seleciona todos os elementos *a*\n",
    "* *: seleciona dos os elementos do código HTML\n",
    "* body *: seleciona todos *h1, h2, div* e a dentro de *body*\n",
    "* div a: seleciona todos *a* dentro de *div*\n",
    "* h1 + p: seleciona o *p* imediatamente depois de *h1*\n",
    "* h1 ~ p: seleciona todos os *p* precedidos pelo *h1*\n",
    "* h1,p: seleciona todos os elementos *h1* e *p*.\n",
    "* div > a: seleciona todos os elementos *a* que são diretamente filhos da *div*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ID and class selectors</h3>\n",
    "\n",
    "*id* e *class* são conhecidas como atributos globais. \n",
    "\n",
    "* **.header**: seleciona o elemento de class='header'\n",
    "* **.plan**: seleciona **a** com class='plan'\n",
    "* **div.link**: seleciona um elemento com **id=link**\n",
    "* **a#link**: seleciona os elementos **a** com **id='link**\n",
    "* **a.plan**: seleciona os elementos **a** com a **class=plan**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Attribute selectors</h3>\n",
    "\n",
    "Os seletores de atribudo são usados para definir seletores com atributos disponíveis.\n",
    "\n",
    "* **a[href*='domain']**: seleciona os elementos **a** que contém **domain** no **href**.\n",
    "* **a[href^='mailto']**: seleciona os elementos **a** que começam com **mailto** do atributo **href**.\n",
    "* **a[href$='pdf']**: seleciona os elementos **a** que tem **pdf** no final do atributo **href**.\n",
    "* **[href~=do]**: seleciona todos os elementos com o atributo **href** que combinam com o valor **do**.\n",
    "* **[class]**: seleciona todos os elementos ou **p**,**div** e **a** com o atributo **class**.\n",
    "* **[class=plan]**: seleciona todos os elementos com a **class=plan**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pseudo selectors</h3>\n",
    "\n",
    "Os pseudoseletores são um conjunto de opções úteis quando se trata de identificar ou selecionar os elementos com base em sua posição.\n",
    "\n",
    "* **a:gt(0)**: seleciona todos os elementos **a** exceto aqueles indexados de **a** na posição (0).\n",
    "* **a:eq(2)**: seleciona os elementos **a** indexados na posição 2.\n",
    "* **a:first-child**: seleciona cada elemento **a** que é o primeiro filho do nó pai.\n",
    "* **a:last-child**: seleciona cada elemento **a** que for o último filho do nó pai.\n",
    "* **a:last-of-type**: seleciona o último elemento **a** do seu nó pai.\n",
    "* **:not(p)**: seleciona todos os elementos exceto **p**.\n",
    "* **a:nth-child(1)**; seleciona cada elemento **a** do primeiro filho do seu nó pai.\n",
    "* **a:nth-last-child(3)**: seleciona cada 3º **a** do último filho de seu nó pai.\n",
    "* **a:nth-of-type(3)**: seleciona cada 3º elemento do seus pais.\n",
    "* **a:nth-last-of-type**: seleciona cada elemento **a** na 3ª posição a partir do último, de seu nó pai.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Scraping usando a biblioteca lxml</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element menus at 0x140cfa08600>\n",
      "<class 'lxml.etree._Element'>\n"
     ]
    }
   ],
   "source": [
    "# Exemplo Nr 1 - lendo xml de um arquivo e percorrendo seus elementos.\n",
    "\n",
    "from lxml import etree\n",
    "xml = open('food.xml', 'rb').read()\n",
    "tree = etree.XML(xml)\n",
    "print(tree)\n",
    "print(type(tree))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "menus - \n",
      "  \n",
      "food - \n",
      "    \n",
      "name - Butter Milk with Vanilla\n",
      "price - $3.99\n",
      "description - Rich tangy buttermilk with vanilla essence\n",
      "rating - 5.0\n",
      "feedback - 6\n",
      "food - \n",
      "    \n",
      "name - Fish and Chips\n",
      "price - $4.99\n",
      "description - Crispy fried Chips and Fish served with lemon and malt vinegar\n",
      "rating - 5.0\n",
      "feedback - 10\n",
      "food - \n",
      "    \n",
      "name - Egg Roll\n",
      "price - $3.99\n",
      "description - Fresh egg rolls filled with ground chicken, carrot, cabbage\n",
      "rating - 4.0\n",
      "feedback - 8\n",
      "food - \n",
      "    \n",
      "name - Pineapple Cake\n",
      "price - $3.99\n",
      "description - Crushed Pineapple mixed with vanilla, eggs and lemon juice\n",
      "rating - 5.0\n",
      "feedback - 9\n",
      "food - \n",
      "    \n",
      "name - Eggs and Bacon\n",
      "price - $5.50\n",
      "description - Served with rice and fresh fruit\n",
      "rating - 4.5\n",
      "feedback - 4\n",
      "food - \n",
      "    \n",
      "name - Orange Juice\n",
      "price - $2.99\n",
      "description - Fresh Orange juice served\n",
      "rating - 4.9\n",
      "feedback - 10\n"
     ]
    }
   ],
   "source": [
    "# Vamos percorrer o arquivo \n",
    "\n",
    "for element in tree.iter():\n",
    "    print(\"%s - %s\" % (element.tag, element.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name - Butter Milk with Vanilla\n",
      "price - $3.99\n",
      "name - Fish and Chips\n",
      "price - $4.99\n",
      "name - Egg Roll\n",
      "price - $3.99\n",
      "name - Pineapple Cake\n",
      "price - $3.99\n",
      "name - Eggs and Bacon\n",
      "price - $5.50\n",
      "name - Orange Juice\n",
      "price - $2.99\n"
     ]
    }
   ],
   "source": [
    "for element in tree.iter('price','name'):\n",
    "    print('%s - %s' % (element.tag, element.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Butter Milk with Vanilla\n",
      "Fish and Chips\n",
      "Egg Roll\n",
      "Pineapple Cake\n",
      "Eggs and Bacon\n",
      "Orange Juice\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "# Lendo e parse o arquivo\n",
    "tree = etree.parse('food.xml')\n",
    "\n",
    "# Iterando através do 'nome' e imprimindo o texto.\n",
    "for element in tree.iter('name'):\n",
    "    print(element.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name - Butter Milk with Vanilla\n",
      "rating - 5.0\n",
      "feedback - 6\n",
      "name - Fish and Chips\n",
      "rating - 5.0\n",
      "feedback - 10\n",
      "name - Egg Roll\n",
      "rating - 4.0\n",
      "feedback - 8\n",
      "name - Pineapple Cake\n",
      "rating - 5.0\n",
      "feedback - 9\n",
      "name - Eggs and Bacon\n",
      "rating - 4.5\n",
      "feedback - 4\n",
      "name - Orange Juice\n",
      "rating - 4.9\n",
      "feedback - 10\n"
     ]
    }
   ],
   "source": [
    "# Para multiplos elementos podemos iterar da seguinte forma:\n",
    "\n",
    "for element in tree.iter('name', 'rating', 'feedback'):\n",
    "    print(f\"{element.tag} - {element.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo documento HTML usando lxml.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'lxml.html.HtmlElement'>\n",
      "<class 'lxml.etree._ElementTree'>\n"
     ]
    }
   ],
   "source": [
    "from lxml import html\n",
    "from urllib.request import urlopen\n",
    "root = html.parse(urlopen('http://httpbin.org/forms/post')).getroot()\n",
    "tree = html.parse(urlopen('http://httpbin.org/forms/post'))\n",
    "\n",
    "print(type(root)) #<class 'lxml.html.HtmlElement'>\n",
    "print(type(tree)) #<class 'lxml.etree._ElementTree'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__bool__', '__class__', '__contains__', '__copy__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_init', 'addnext', 'addprevious', 'append', 'attrib', 'base', 'base_url', 'body', 'classes', 'clear', 'cssselect', 'drop_tag', 'drop_tree', 'extend', 'find', 'find_class', 'find_rel_links', 'findall', 'findtext', 'forms', 'get', 'get_element_by_id', 'getchildren', 'getiterator', 'getnext', 'getparent', 'getprevious', 'getroottree', 'head', 'index', 'insert', 'items', 'iter', 'iterancestors', 'iterchildren', 'iterdescendants', 'iterfind', 'iterlinks', 'itersiblings', 'itertext', 'keys', 'label', 'make_links_absolute', 'makeelement', 'nsmap', 'prefix', 'remove', 'replace', 'resolve_base_href', 'rewrite_links', 'set', 'sourceline', 'tag', 'tail', 'text', 'text_content', 'values', 'xpath']\n"
     ]
    }
   ],
   "source": [
    "# O HTML Element \"root\" tem várias propriedades:\n",
    "print(dir(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer name: \n",
      "Customer name: \n"
     ]
    }
   ],
   "source": [
    "# Encontrar <p> no root.\n",
    "p = root.find('.//p') # Primeiro <p> do root\n",
    "print(p.text_content())\n",
    "print(root.findtext('.//p/label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer name: \n",
      "Telephone: \n",
      "E-mail address: \n",
      "  Small \n",
      "  Medium \n",
      "  Large \n",
      "  Bacon \n",
      "  Extra Cheese \n",
      "  Onion \n",
      "  Mushroom \n",
      "Preferred delivery time: \n",
      "Delivery instructions: \n",
      "Submit order\n"
     ]
    }
   ],
   "source": [
    "# Podemos utilizar o findall() para iterar todos os elementos no <root>\n",
    "elemP = root.findall('.//p') # Encontrar todos os <p> elementos\n",
    "for p in elemP:\n",
    "    print(p.text_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['small', 'medium', 'large', 'bacon', 'cheese', 'onion', 'mushroom']\n",
      "[' Pizza Size ', ' Pizza Toppings ']\n"
     ]
    }
   ],
   "source": [
    "# O HTMLElement \"root\" suporta Xpath e CSSSelect\n",
    "print(root.xpath('//p/label/input/@value'))\n",
    "print(root.xpath('//legend/text()'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer name: \n",
      "Telephone: \n",
      "E-mail address: \n",
      "  Small \n",
      "  Medium \n",
      "  Large \n",
      "  Bacon \n",
      "  Extra Cheese \n",
      "  Onion \n",
      "  Mushroom \n",
      "Preferred delivery time: \n",
      "Delivery instructions: \n"
     ]
    }
   ],
   "source": [
    "# CCSelect traduz CSS selectors em expressões XPath and utiliza:\n",
    "# Imprime text_content() para os rótulos dentro <p>\n",
    "\n",
    "for e in root.cssselect('p label'):\n",
    "    print(e.text_content())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://httpbin.org/post\n",
      "['method', 'action']\n",
      "[('method', 'post'), ('action', '/post')]\n",
      "POST\n"
     ]
    }
   ],
   "source": [
    "# Podemos explorar os elementos do html <form>\n",
    "\n",
    "print(root.forms[0].action) # retorna a URL\n",
    "print(root.forms[0].keys()) # Retorna uma lista com os elementos chaves\n",
    "print(root.forms[0].items()) # Retorna uma lista de tuplas com chave e valor\n",
    "print(root.forms[0].method) # Retorna o valor para o método atributo que é HTTP request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo e analisando HTML para recuperar atributos de elemento de tipo de formulário HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element: input\n",
      "\tvalues(): ['custname']\n",
      "\tattrib: {'name': 'custname'}\n",
      "\titems(): [('name', 'custname')]\n",
      "\tkeys(): ['name']\n",
      "\n",
      "\n",
      "Element: input\n",
      "\tvalues(): ['tel', 'custtel']\n",
      "\tattrib: {'type': 'tel', 'name': 'custtel'}\n",
      "\titems(): [('type', 'tel'), ('name', 'custtel')]\n",
      "\tkeys(): ['type', 'name']\n",
      "\n",
      "\n",
      "Element: input\n",
      "\tvalues(): ['email', 'custemail']\n",
      "\tattrib: {'type': 'email', 'name': 'custemail'}\n",
      "\titems(): [('type', 'email'), ('name', 'custemail')]\n",
      "\tkeys(): ['type', 'name']\n",
      "\n",
      "\n",
      "Element: input\n",
      "\tvalues(): ['radio', 'size', 'small']\n",
      "\tattrib: {'type': 'radio', 'name': 'size', 'value': 'small'}\n",
      "\titems(): [('type', 'radio'), ('name', 'size'), ('value', 'small')]\n",
      "\tkeys(): ['type', 'name', 'value']\n",
      "\n",
      "\n",
      "Element: input\n",
      "\tvalues(): ['radio', 'size', 'medium']\n",
      "\tattrib: {'type': 'radio', 'name': 'size', 'value': 'medium'}\n",
      "\titems(): [('type', 'radio'), ('name', 'size'), ('value', 'medium')]\n",
      "\tkeys(): ['type', 'name', 'value']\n",
      "\n",
      "\n",
      "Element: input\n",
      "\tvalues(): ['radio', 'size', 'large']\n",
      "\tattrib: {'type': 'radio', 'name': 'size', 'value': 'large'}\n",
      "\titems(): [('type', 'radio'), ('name', 'size'), ('value', 'large')]\n",
      "\tkeys(): ['type', 'name', 'value']\n",
      "\n",
      "\n",
      "Element: input\n",
      "\tvalues(): ['checkbox', 'topping', 'bacon']\n",
      "\tattrib: {'type': 'checkbox', 'name': 'topping', 'value': 'bacon'}\n",
      "\titems(): [('type', 'checkbox'), ('name', 'topping'), ('value', 'bacon')]\n",
      "\tkeys(): ['type', 'name', 'value']\n",
      "\n",
      "\n",
      "Element: input\n",
      "\tvalues(): ['checkbox', 'topping', 'cheese']\n",
      "\tattrib: {'type': 'checkbox', 'name': 'topping', 'value': 'cheese'}\n",
      "\titems(): [('type', 'checkbox'), ('name', 'topping'), ('value', 'cheese')]\n",
      "\tkeys(): ['type', 'name', 'value']\n",
      "\n",
      "\n",
      "Element: input\n",
      "\tvalues(): ['checkbox', 'topping', 'onion']\n",
      "\tattrib: {'type': 'checkbox', 'name': 'topping', 'value': 'onion'}\n",
      "\titems(): [('type', 'checkbox'), ('name', 'topping'), ('value', 'onion')]\n",
      "\tkeys(): ['type', 'name', 'value']\n",
      "\n",
      "\n",
      "Element: input\n",
      "\tvalues(): ['checkbox', 'topping', 'mushroom']\n",
      "\tattrib: {'type': 'checkbox', 'name': 'topping', 'value': 'mushroom'}\n",
      "\titems(): [('type', 'checkbox'), ('name', 'topping'), ('value', 'mushroom')]\n",
      "\tkeys(): ['type', 'name', 'value']\n",
      "\n",
      "\n",
      "Element: input\n",
      "\tvalues(): ['time', '11:00', '21:00', '900', 'delivery']\n",
      "\tattrib: {'type': 'time', 'min': '11:00', 'max': '21:00', 'step': '900', 'name': 'delivery'}\n",
      "\titems(): [('type', 'time'), ('min', '11:00'), ('max', '21:00'), ('step', '900'), ('name', 'delivery')]\n",
      "\tkeys(): ['type', 'min', 'max', 'step', 'name']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "response = requests.get('http://httpbin.org/forms/post')\n",
    "# Construindo a árvore DOM\n",
    "\n",
    "tree = html.fromstring(response.text)\n",
    "\n",
    "for element in tree.iter('input'):\n",
    "    print(f\"Element: {element.tag}\\n\\tvalues(): {element.values()}\\n\\tattrib: {element.attrib}\\n\\titems(): {element.items()}\\n\\tkeys(): {element.keys()}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping usando lxml\n",
    "### Extraindo dados selecionados de uma única página usando lxml.html.xpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "musicUrl = \"http://books.toscrape.com/catalogue/category/books/music_14/index.html\"\n",
    "doc = lxml.html.parse(musicUrl)\n",
    "\n",
    "# Elementos Base\n",
    "articles = doc.xpath(\"//*[@id='default']/div/div/div/div/section/div[2]/ol/li[1]/article\")[0]\n",
    "\n",
    "# Elementos individuais\n",
    "title = articles.xpath('//h3/a/text()')\n",
    "price = articles.xpath(\"//div[2]/p[contains(@class,'price_color')]/text()\")\n",
    "availability = articles.xpath(\"//div[2]/p[2][contains(@class,'availability')]/text()[normalize-space()]\")\n",
    "imageUrl = articles.xpath(\"//div[1][contains(@class,'image_container')]/a/img/@src\")\n",
    "starRating = articles.xpath(\"//p[contains(@class,'star-rating')]/@class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rip it Up and ...', 'Our Band Could Be ...', 'How Music Works', 'Love Is a Mix ...', 'Please Kill Me: The ...', \"Kill 'Em and Leave: ...\", 'Chronicles, Vol. 1', 'This Is Your Brain ...', 'Orchestra of Exiles: The ...', 'No One Here Gets ...', 'Life', 'Old Records Never Die: ...', 'Forever Rockers (The Rocker ...']\n",
      "['£35.02', '£57.25', '£37.32', '£18.03', '£31.19', '£45.05', '£52.60', '£38.40', '£12.36', '£20.02', '£31.58', '£55.66', '£28.80']\n",
      "['In stock', 'In stock', 'In stock', 'In stock', 'In stock', 'In stock', 'In stock', 'In stock', 'In stock', 'In stock', 'In stock', 'In stock', 'In stock']\n",
      "['http://books.toscrape.com/media/cache/81/c4/81c4a973364e17d01f217e1188253d5e.jpg', 'http://books.toscrape.com/media/cache/54/60/54607fe8945897cdcced0044103b10b6.jpg', 'http://books.toscrape.com/media/cache/5c/c8/5cc8e107246cb478960d4f0aba1e1c8e.jpg', 'http://books.toscrape.com/media/cache/a2/6d/a26d8449abb3381e09126eda5f4e8151.jpg', 'http://books.toscrape.com/media/cache/06/f1/06f185c0be2ad6e2fe059464c03f1b47.jpg', 'http://books.toscrape.com/media/cache/85/42/8542841f5644a6daf433504f1e106e97.jpg', 'http://books.toscrape.com/media/cache/11/fc/11fc94453c4dc0d68543971d7843afb0.jpg', 'http://books.toscrape.com/media/cache/35/a4/35a4a7c6c76c4e82186753078e441654.jpg', 'http://books.toscrape.com/media/cache/15/de/15de75548ee9a4c6be1420ee309c03e0.jpg', 'http://books.toscrape.com/media/cache/7a/7e/7a7eb52e7075a5305522948375c1316e.jpg', 'http://books.toscrape.com/media/cache/99/97/9997eda658c2fe50e724171f9c2a2b0b.jpg', 'http://books.toscrape.com/media/cache/7e/94/7e947f3dd04f178175b85123829467a9.jpg', 'http://books.toscrape.com/media/cache/7f/b0/7fb03a053c270000667a50dd8d594843.jpg']\n",
      "['Five', 'Three', 'Two', 'One', 'Four', 'Five', 'Two', 'One', 'Three', 'Five', 'Five', 'Two', 'Three']\n"
     ]
    }
   ],
   "source": [
    "# Limpando e formatando as expressões\n",
    "stock = list(map(lambda stock:stock.strip(), availability))\n",
    "images = list(map(lambda img:img.replace('../../../..', 'http://books.toscrape.com'),imageUrl))\n",
    "rating = list(map(lambda rating:rating.replace('star-rating ',''), starRating))\n",
    "\n",
    "print(title)\n",
    "print(price)\n",
    "print(stock)\n",
    "print(images)\n",
    "print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rip it Up and ...',\n",
       "  '£35.02',\n",
       "  'In stock',\n",
       "  'http://books.toscrape.com/media/cache/81/c4/81c4a973364e17d01f217e1188253d5e.jpg',\n",
       "  'Five'),\n",
       " ('Our Band Could Be ...',\n",
       "  '£57.25',\n",
       "  'In stock',\n",
       "  'http://books.toscrape.com/media/cache/54/60/54607fe8945897cdcced0044103b10b6.jpg',\n",
       "  'Three'),\n",
       " ('How Music Works',\n",
       "  '£37.32',\n",
       "  'In stock',\n",
       "  'http://books.toscrape.com/media/cache/5c/c8/5cc8e107246cb478960d4f0aba1e1c8e.jpg',\n",
       "  'Two'),\n",
       " ('Love Is a Mix ...',\n",
       "  '£18.03',\n",
       "  'In stock',\n",
       "  'http://books.toscrape.com/media/cache/a2/6d/a26d8449abb3381e09126eda5f4e8151.jpg',\n",
       "  'One'),\n",
       " ('Please Kill Me: The ...',\n",
       "  '£31.19',\n",
       "  'In stock',\n",
       "  'http://books.toscrape.com/media/cache/06/f1/06f185c0be2ad6e2fe059464c03f1b47.jpg',\n",
       "  'Four'),\n",
       " (\"Kill 'Em and Leave: ...\",\n",
       "  '£45.05',\n",
       "  'In stock',\n",
       "  'http://books.toscrape.com/media/cache/85/42/8542841f5644a6daf433504f1e106e97.jpg',\n",
       "  'Five'),\n",
       " ('Chronicles, Vol. 1',\n",
       "  '£52.60',\n",
       "  'In stock',\n",
       "  'http://books.toscrape.com/media/cache/11/fc/11fc94453c4dc0d68543971d7843afb0.jpg',\n",
       "  'Two'),\n",
       " ('This Is Your Brain ...',\n",
       "  '£38.40',\n",
       "  'In stock',\n",
       "  'http://books.toscrape.com/media/cache/35/a4/35a4a7c6c76c4e82186753078e441654.jpg',\n",
       "  'One'),\n",
       " ('Orchestra of Exiles: The ...',\n",
       "  '£12.36',\n",
       "  'In stock',\n",
       "  'http://books.toscrape.com/media/cache/15/de/15de75548ee9a4c6be1420ee309c03e0.jpg',\n",
       "  'Three'),\n",
       " ('No One Here Gets ...',\n",
       "  '£20.02',\n",
       "  'In stock',\n",
       "  'http://books.toscrape.com/media/cache/7a/7e/7a7eb52e7075a5305522948375c1316e.jpg',\n",
       "  'Five'),\n",
       " ('Life',\n",
       "  '£31.58',\n",
       "  'In stock',\n",
       "  'http://books.toscrape.com/media/cache/99/97/9997eda658c2fe50e724171f9c2a2b0b.jpg',\n",
       "  'Five'),\n",
       " ('Old Records Never Die: ...',\n",
       "  '£55.66',\n",
       "  'In stock',\n",
       "  'http://books.toscrape.com/media/cache/7e/94/7e947f3dd04f178175b85123829467a9.jpg',\n",
       "  'Two'),\n",
       " ('Forever Rockers (The Rocker ...',\n",
       "  '£28.80',\n",
       "  'In stock',\n",
       "  'http://books.toscrape.com/media/cache/7f/b0/7fb03a053c270000667a50dd8d594843.jpg',\n",
       "  'Three')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Os dados coletados pode ser mesclados em um objeto python.\n",
    "# Mesclando todos.\n",
    "\n",
    "dataSet = zip(title, price, stock, images, rating)\n",
    "list(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop com XPath scraping de dados de várias páginas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "from lxml.etree import XPath\n",
    "\n",
    "baseUrl = \"http://books.toscrape.com/\"\n",
    "\n",
    "# Principal URL\n",
    "bookUrl = \"http://books.toscrape.com/catalogue/category/books/food-and-drink_33/index.html\"\n",
    "\n",
    "# Pagina URL padrão obtida (ex: page-1.html, page-2.html...)\n",
    "pageUrl = \"http://books.toscrape.com/catalogue/category/books/food-and-drink_33/page-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in Dataset: 0\n",
      "30 Results, showing 20 Articles per page\n",
      "Scraping Page 1 of 2. NextPage > page-2.html\n",
      "Rows in Dataset: 20\n",
      "Scraping Page 2 of 2\n",
      "[['Foolproof Preserving: A Guide ...', '£30.52', 'In stock', 'http://books.toscrape.com//media/cache/9f/59/9f59f01fa916a7bb8f0b28a4012179a4.jpg', 'Three'], ['The Pioneer Woman Cooks: ...', '£56.41', 'In stock', 'http://books.toscrape.com//media/cache/b7/f4/b7f4843dbe062d44be1ffcfa16b2faa4.jpg', 'One'], ['My Paris Kitchen: Recipes ...', '£33.37', 'In stock', 'http://books.toscrape.com//media/cache/f5/65/f565af3d9dd20a1ad72a1e7c4157387d.jpg', 'Two'], ['Mama Tried: Traditional Italian ...', '£14.02', 'In stock', 'http://books.toscrape.com//media/cache/10/c6/10c61093002db1fec4089d8076678624.jpg', 'Four'], ['Layered: Baking, Building, and ...', '£40.11', 'In stock', 'http://books.toscrape.com//media/cache/98/d1/98d1c979c4bac9e147a6718946578b0f.jpg', 'One'], ['The Nerdy Nummies Cookbook: ...', '£37.34', 'In stock', 'http://books.toscrape.com//media/cache/61/bd/61bdfe3950643c47d70c37c4123530f3.jpg', 'Five'], ['The Love and Lemons ...', '£37.60', 'In stock', 'http://books.toscrape.com//media/cache/0d/1f/0d1f3f934460f5a50aaa8c366641234c.jpg', 'Two'], ['The Cookies & Cups ...', '£41.25', 'In stock', 'http://books.toscrape.com//media/cache/54/89/54899b4584e941ceced511d81092c88a.jpg', 'One'], ['Deliciously Ella Every Day: ...', '£42.16', 'In stock', 'http://books.toscrape.com//media/cache/20/f2/20f28657b49f8cb24ed2ec6448bb6df3.jpg', 'Three'], ['The Help Yourself Cookbook ...', '£28.77', 'In stock', 'http://books.toscrape.com//media/cache/c4/dc/c4dcec6f513eaca3f0f3c748d834c46d.jpg', 'Three'], [\"It's All Easy: Healthy, ...\", '£19.55', 'In stock', 'http://books.toscrape.com//media/cache/fe/67/fe67c381d6a0c4c00a7c191d16939554.jpg', 'One'], ['Barefoot Contessa Back to ...', '£28.01', 'In stock', 'http://books.toscrape.com//media/cache/b8/38/b838b65e0e1ac3a9b498dfb1bf004420.jpg', 'One'], ['Barefoot Contessa at Home: ...', '£50.62', 'In stock', 'http://books.toscrape.com//media/cache/74/aa/74aa29b1ba4147eaf5b46671bf235861.jpg', 'Five'], ['My Kitchen Year: 136 ...', '£11.53', 'In stock', 'http://books.toscrape.com//media/cache/76/a1/76a1516c8d9c3e620626f30840013a85.jpg', 'Two'], ['Everyday Italian: 125 Simple ...', '£20.10', 'In stock', 'http://books.toscrape.com//media/cache/5a/64/5a6499d41ccaad4c4f7eeaa90e16345a.jpg', 'Five'], ['A la Mode: 120 ...', '£38.77', 'In stock', 'http://books.toscrape.com//media/cache/98/19/9819ff3a8290dc6ab8797d00de5ec554.jpg', 'One'], ['Cravings: Recipes for What ...', '£20.50', 'In stock', 'http://books.toscrape.com//media/cache/ae/5c/ae5ca435fb095e374d2c2aa9f7b6f380.jpg', 'Three'], ['The Moosewood Cookbook: Recipes ...', '£12.34', 'In stock', 'http://books.toscrape.com//media/cache/d4/53/d453cfb6c08dbf76d200ffa858bc9979.jpg', 'Four'], ['32 Yolks', '£53.63', 'In stock', 'http://books.toscrape.com//media/cache/1d/1f/1d1fbd89f0290275b9166877663ee9f5.jpg', 'Two'], ['Naturally Lean: 125 Nourishing ...', '£11.38', 'In stock', 'http://books.toscrape.com//media/cache/e6/b6/e6b66353f9325518994dd8b564290fd7.jpg', 'Five'], ['How to Cook Everything ...', '£46.01', 'In stock', 'http://books.toscrape.com//media/cache/59/2d/592dc2dee11b798780f5ae613b970a34.jpg', 'Four'], ['How to Be a ...', '£28.25', 'In stock', 'http://books.toscrape.com//media/cache/e2/5c/e25cbc27ebc12e47cdf3f7adc87cccdc.jpg', 'Two'], ['The Barefoot Contessa Cookbook', '£59.92', 'In stock', 'http://books.toscrape.com//media/cache/dd/07/dd07bd0c443756b9dc260813c1949b4f.jpg', 'Five'], ['Better Homes and Gardens ...', '£39.61', 'In stock', 'http://books.toscrape.com//media/cache/75/82/7582e20b84f603358a8d55cd6a0a50f4.jpg', 'Three'], ['The Power Greens Cookbook: ...', '£11.05', 'In stock', 'http://books.toscrape.com//media/cache/82/1d/821d2c02dcd0a10fc9d533917482746e.jpg', 'Five'], ['Mexican Today: New and ...', '£24.91', 'In stock', 'http://books.toscrape.com//media/cache/5d/02/5d029bff299cdb777e06f35800faa628.jpg', 'Five'], ['Vegan Vegetarian Omnivore: Dinner ...', '£13.66', 'In stock', 'http://books.toscrape.com//media/cache/80/63/80631f8bca036361343fdce528725654.jpg', 'Two'], ['The Smitten Kitchen Cookbook', '£23.59', 'In stock', 'http://books.toscrape.com//media/cache/8e/09/8e09faaea71886048b27959e607e6c7b.jpg', 'One'], ['The Art of Simple ...', '£34.32', 'In stock', 'http://books.toscrape.com//media/cache/96/57/9657c6d89024e343879a7b5512474f1e.jpg', 'Three'], ['Hungry Girl Clean & ...', '£33.14', 'In stock', 'http://books.toscrape.com//media/cache/6f/c4/6fc450625cd672e871a6176f74909be2.jpg', 'Three']]\n"
     ]
    }
   ],
   "source": [
    "import lxml.html\n",
    "from lxml.etree import XPath\n",
    "\n",
    "baseUrl = \"http://books.toscrape.com/\"\n",
    "bookUrl = \"http://books.toscrape.com/catalogue/category/books/food-and-drink_33/index.html\"\n",
    "pageUrl = \"http://books.toscrape.com/catalogue/category/books/food-and-drink_33/page-\"\n",
    "\n",
    "dataSet = []\n",
    "page=1\n",
    "totalPages=1\n",
    "while(page<=totalPages):\n",
    "    print(\"Rows in Dataset: \"+str(len(dataSet)))\n",
    "\n",
    "    if(page==1):\n",
    "        doc = lxml.html.parse(pageUrl+str(page)+\".html\").getroot()\n",
    "        perPageArticles = doc.xpath(\"//*[@id=\\\"default\\\"]//form/strong[3]/text()\")\n",
    "        totalArticles = doc.xpath(\"//*[@id=\\\"default\\\"]//form/strong[1]/text()\")\n",
    "        totalPages = round(int(totalArticles[0])/int(perPageArticles[0]))\n",
    "        print(str(totalArticles[0])+\" Results, showing \"+str(perPageArticles[0])+\" Articles per page\")\n",
    "    else:\n",
    "        doc = lxml.html.parse(pageUrl+str(page)+\".html\").getroot()\n",
    "\n",
    "    #used to find page url pattern\n",
    "    nextPage = doc.xpath(\"//*[@id=\\\"default\\\"]//ul[contains(@class,'pager')]/li[2][contains(@class,'next')]/a/@href\")\n",
    "    if len(nextPage)>0:    \n",
    "        print(\"Scraping Page \"+str(page)+\" of \"+str(totalPages)+\". NextPage > \"+str(nextPage[0]))\n",
    "    else:\n",
    "        print(\"Scraping Page \"+str(page)+\" of \"+str(totalPages))\n",
    "    \n",
    "    articles = XPath(\"//*[@id='default']//ol/li[position()>0]\")\n",
    "    titlePath = XPath(\".//article[contains(@class,'product_pod')]/h3/a/text()\")\n",
    "    pricePath = XPath(\".//article/div[2]/p[contains(@class,'price_color')]/text()\")\n",
    "    stockPath = XPath(\".//article/div[2]/p[2][contains(@class,'availability')]/text()[normalize-space()]\")\n",
    "    imagePath = XPath(\".//article/div[1][contains(@class,'image_container')]/a/img/@src\")\n",
    "    starRating = XPath(\".//article/p[contains(@class,'star-rating')]/@class\")\n",
    "    \n",
    "    for row in articles(doc):\n",
    "        title = titlePath(row)[0]\n",
    "        price = pricePath(row)[0]\n",
    "        availability = stockPath(row)[0].strip()\n",
    "        image = imagePath(row)[0]\n",
    "        rating = starRating(row)[0]\n",
    "    \n",
    "        dataSet.append([title,price,availability,image.replace('../../../..',baseUrl),rating.replace('star-rating ','')])\n",
    "\n",
    "    page+=1\n",
    "\n",
    "print(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando lxml.cssselect para extrair o conteúdo de uma página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "from lxml.cssselect import CSSSelector\n",
    "\n",
    "url = \"https://developer.ibm.com/announcements/\"\n",
    "url_get = requests.get(url)\n",
    "\n",
    "tree = html.document_fromstring(url_get.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
